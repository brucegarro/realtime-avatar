# Realtime Avatar: Multilingual Conversational Avatar System

A low-latency, multilingual conversational avatar system with GPU acceleration that generates realistic talking-head videos using voice cloning and AI animation.

## ðŸŽ¯ Project Overview

**Current Phase**: Phase 1 (Script â†’ Video MVP) âœ… **+ GPU Accelerated**  
**Performance**: 93x faster with M3 MPS acceleration

This system creates a digital avatar that:
- ðŸ—£ï¸ Speaks in Bruce's cloned voice (multilingual: EN/ZH/ES)
- ðŸŽ­ Animates from reference images
- âš¡ **Faster than realtime** generation with GPU acceleration
- ðŸ’° Scales to zero cost when idle (Cloud Run GPU)
- ðŸ”§ Supports local development (M3 MPS) and cloud production (GCP CUDA)

## ï¿½ Performance

| Metric | CPU Only | M3 MPS | Improvement |
|--------|----------|---------|-------------|
| TTS Generation | ~126s for 4.5s audio | ~2.4s for 4.5s audio | **52x faster** |
| Speed vs Realtime | 27x slower | 0.54x (faster!) | **50x improvement** |
| Total Generation | >120s | <2s | **60x faster** |

## ï¿½ðŸ“‹ Development Phases

- **Phase 1** âœ… **COMPLETE**: Script â†’ Pre-rendered video (GPU accelerated)
- **Phase 2** ðŸš§ (Next): Semi-interactive chat with response clips
- **Phase 3** ðŸ“… (Future): Real-time WebRTC streaming conversation

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU Service (Native, Port 8001)     â”‚
â”‚  - TTS with MPS/CUDA acceleration   â”‚
â”‚  - Video Gen (future)                â”‚
â”‚  - Lip Sync (future)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Runtime Service (Docker, Port 8000) â”‚
â”‚  - FastAPI orchestration             â”‚
â”‚  - Business logic                    â”‚
â”‚  - Asset management                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evaluator (Automated Testing)       â”‚
â”‚  - Test scenarios                    â”‚
â”‚  - Performance metrics               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Deployment Modes
- **Local Dev**: Docker runtime + native GPU service (M3 MPS)
- **Production**: Cloud Run + GCP GPU instance (CUDA)

## ðŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.9+ (for GPU service)
- ffmpeg
- macOS M1/M2/M3 (for local GPU) or Linux

### Setup

1. **Extract voice samples from videos**:
### Local Development (with GPU Acceleration)

1. **Setup GPU service** (for M3 Macs):
```bash
cd runtime
./setup_gpu_service.sh
./run_gpu_service.sh  # Runs in background on port 8001
```

2. **Extract voice samples**:
```bash
./scripts/extract_voice_samples.sh
```

3. **Build Docker images**:
```bash
./scripts/build_images.sh
```

4. **Start runtime service**:
```bash
docker compose up runtime  # Automatically connects to GPU service
```

5. **Test generation**:
```bash
curl -X POST http://localhost:8000/api/v1/generate \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello from GPU acceleration!", "language": "en"}'
```

6. **Run evaluator** (optional):
```bash
docker compose --profile evaluator up evaluator
```

Or use the all-in-one setup script:
```bash
./scripts/setup_local.sh
```

### Without GPU (CPU only)

Set `USE_EXTERNAL_GPU_SERVICE=false` in `docker-compose.yml` to run TTS in Docker (slower).

## ðŸ“ Project Structure

```
realtime-avatar/
â”œâ”€â”€ assets/                  # Reference media
â”‚   â”œâ”€â”€ images/             # Avatar reference images
â”‚   â”œâ”€â”€ videos/             # Reference motion videos
â”‚   â””â”€â”€ voice/              # Voice samples for cloning
â”œâ”€â”€ runtime/                 # Main inference service
â”‚   â”œâ”€â”€ models/             # Model wrappers (TTS, Avatar, ASR, LLM)
â”‚   â”‚   â””â”€â”€ tts_client.py   # GPU service client
â”‚   â”œâ”€â”€ pipelines/          # Generation pipelines
â”‚   â”œâ”€â”€ utils/              # Utilities
â”‚   â”œâ”€â”€ gpu_service.py      # GPU acceleration service (NEW)
â”‚   â”œâ”€â”€ GPU_SERVICE.md      # GPU service documentation
â”‚   â””â”€â”€ app.py              # FastAPI application
â”œâ”€â”€ evaluator/              # Testing & metrics
â”‚   â”œâ”€â”€ scenarios/          # Test scenarios
â”‚   â”œâ”€â”€ metrics/            # Metric calculators
â”‚   â””â”€â”€ run_evaluator.py    # Main runner
â”œâ”€â”€ web/                    # React UI (stub)
â”œâ”€â”€ infrastructure/         # Terraform (stub)
â””â”€â”€ scripts/                # Utility scripts
```

## ðŸ”¬ Testing & Evaluation

The evaluator runs automated tests and generates metrics:
- âœ… English short/medium utterances
- âœ… Chinese (Mandarin) short/medium
- âœ… Spanish short/medium
- âœ… Language switching (ENâ†’ZH, ENâ†’ES, ENâ†’ZHâ†’ES)

### Metrics Collected
- **Latency**: TTS time, avatar rendering time, total time
- **Voice Quality**: Speaker similarity, F0/pitch analysis
- **Language**: Detection accuracy, correctness
- **Lip Sync**: Audio-video coherence (basic heuristic)

### Run Evaluator
```bash
docker compose --profile evaluator up evaluator
```

Results are saved to `evaluator/outputs/` as JSON files.

## ðŸŽ¨ API Usage

### Health Check
```bash
curl http://localhost:8000/health
```

### Generate Video
```bash
curl -X POST http://localhost:8000/api/v1/generate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Hello! I am Bruce'\''s digital avatar.",
    "language": "en",
    "reference_image": "bruce_neutral.jpg"
  }'
```

### Download Generated Video
```bash
curl http://localhost:8000/api/v1/videos/{filename} -o output.mp4
```

## ðŸ› ï¸ Technology Stack

| Component | Technology | Notes |
|-----------|-----------|-------|
| **TTS** | XTTS-v2 | Multilingual voice cloning |
| **Avatar** | LivePortrait | Single-image animation (placeholder) |
| **ASR** | faster-whisper | Phase 3 |
| **LLM** | Qwen-2.5 | Phase 2+ |
| **API** | FastAPI | Python async |
| **Container** | Docker | CPU (local) / GPU (prod) |
| **Orchestration** | Docker Compose | Local dev |
| **Cloud** | GCP Cloud Run GPU | Production |

## ðŸŽ¯ Performance Targets

- **Resolution**: 256p-360p (latency > quality)
- **FPS**: 25-30
- **Latency** (Phase 3): 450-900ms end-to-end
- **Cost**: < $100/month with scale-to-zero

## ðŸ”§ Configuration

Edit `.env` file (copy from `.env.example`):

```bash
MODE=local          # local or production
DEVICE=cpu          # cpu or cuda
LOG_LEVEL=info
DEFAULT_REFERENCE_IMAGE=bruce_neutral.jpg
```

## ðŸ“Š Development Status

### âœ… Completed (Phase 1)
- [x] Project structure and Docker setup
- [x] Runtime service with FastAPI
- [x] XTTS-v2 TTS integration
- [x] Basic avatar animation (placeholder)
- [x] Phase 1 pipeline (script â†’ video)
- [x] Evaluator with test scenarios
- [x] Metrics collection framework
- [x] Voice sample extraction

### ðŸš§ In Progress
- [ ] LivePortrait full integration
- [ ] Voice quality optimization
- [ ] Model download automation

### ðŸ“… Planned (Phase 2)
- [ ] Qwen LLM integration
- [ ] Semi-interactive chat pipeline
- [ ] React web UI
- [ ] Cloud deployment (Terraform)

### ðŸ“… Planned (Phase 3)
- [ ] faster-whisper ASR
- [ ] Real-time streaming
- [ ] WebRTC integration
- [ ] Production optimization

## ðŸ“ Notes

### Model Downloads
On first run, XTTS-v2 models (~2GB) will be downloaded automatically. This may take several minutes.

### Voice Samples
Voice reference samples are extracted from the video files in `assets/videos/`. Ensure videos contain clear speech in each language (EN/ZH/ES).

### LivePortrait
Current implementation uses a simple video generation as a placeholder. Full LivePortrait integration requires:
- Cloning the LivePortrait repository
- Downloading pre-trained models
- GPU for acceptable performance

## ðŸ¤ Contributing

This is a personal project following the specification in `PROJECT_SPEC.md`.

## ðŸ“„ License

Private project - All rights reserved.

---

**Last Updated**: November 6, 2025
**Phase**: 1 (MVP)
**Status**: Development
