# Realtime Avatar: Realtime Avatar System

A low-latency, multilingual conversational avatar system that generates realistic talking-head videos using voice cloning and AI animation.

## ðŸŽ¯ Project Overview

**Current Phase**: Phase 1 (Script â†’ Video MVP)

This system creates a digital avatar that:
- ðŸ—£ï¸ Speaks in Bruce's cloned voice (multilingual: EN/ZH/ES)
- ðŸŽ­ Animates from reference images
- âš¡ Prioritizes low latency over high resolution
- ðŸ’° Scales to zero cost when idle (Cloud Run GPU)
- ðŸ”§ Supports local development and cloud production

## ðŸ“‹ Development Phases

- **Phase 1** âœ… (Current): Script â†’ Pre-rendered video
- **Phase 2** ðŸš§ (Next): Semi-interactive chat with response clips
- **Phase 3** ðŸ“… (Future): Real-time WebRTC streaming conversation

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI        â”‚ (React, Phase 2+)
â”‚   /avatar       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/WebRTC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Runtime API    â”‚ FastAPI
â”‚  - TTS (XTTS-v2)â”‚ Port 8000
â”‚  - Avatar (LP)  â”‚
â”‚  - ASR/LLM      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evaluator      â”‚ Test & Metrics
â”‚  - Scenarios    â”‚
â”‚  - Metrics      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- ffmpeg
- macOS (for local dev) or Linux

### Setup

1. **Extract voice samples from videos**:
```bash
./scripts/extract_voice_samples.sh
```

2. **Build Docker images**:
```bash
./scripts/build_images.sh
```

3. **Start runtime service**:
```bash
docker compose up runtime
```

4. **Run evaluator** (in another terminal):
```bash
docker compose --profile evaluator up evaluator
```

Or use the all-in-one setup script:
```bash
./scripts/setup_local.sh
```

## ðŸ“ Project Structure

```
realtime-avatar/
â”œâ”€â”€ assets/                  # Reference media
â”‚   â”œâ”€â”€ images/             # Avatar reference images
â”‚   â”œâ”€â”€ videos/             # Reference motion videos
â”‚   â””â”€â”€ voice/              # Voice samples for cloning
â”œâ”€â”€ runtime/                 # Main inference service
â”‚   â”œâ”€â”€ models/             # Model wrappers (TTS, Avatar, ASR, LLM)
â”‚   â”œâ”€â”€ pipelines/          # Generation pipelines
â”‚   â”œâ”€â”€ utils/              # Utilities
â”‚   â””â”€â”€ app.py              # FastAPI application
â”œâ”€â”€ evaluator/              # Testing & metrics
â”‚   â”œâ”€â”€ scenarios/          # Test scenarios
â”‚   â”œâ”€â”€ metrics/            # Metric calculators
â”‚   â””â”€â”€ run_evaluator.py    # Main runner
â”œâ”€â”€ web/                    # React UI (stub)
â”œâ”€â”€ infrastructure/         # Terraform (stub)
â””â”€â”€ scripts/                # Utility scripts
```

## ðŸ”¬ Testing & Evaluation

The evaluator runs automated tests and generates metrics:

### Test Scenarios
- âœ… English short/medium utterances
- âœ… Chinese (Mandarin) short/medium
- âœ… Spanish short/medium
- âœ… Language switching (ENâ†’ZH, ENâ†’ES, ENâ†’ZHâ†’ES)

### Metrics Collected
- **Latency**: TTS time, avatar rendering time, total time
- **Voice Quality**: Speaker similarity, F0/pitch analysis
- **Language**: Detection accuracy, correctness
- **Lip Sync**: Audio-video coherence (basic heuristic)

### Run Evaluator
```bash
docker compose --profile evaluator up evaluator
```

Results are saved to `evaluator/outputs/` as JSON files.

## ðŸŽ¨ API Usage

### Health Check
```bash
curl http://localhost:8000/health
```

### Generate Video
```bash
curl -X POST http://localhost:8000/api/v1/generate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Hello! I am Bruce'\''s digital avatar.",
    "language": "en",
    "reference_image": "bruce_neutral.jpg"
  }'
```

### Download Generated Video
```bash
curl http://localhost:8000/api/v1/videos/{filename} -o output.mp4
```

## ðŸ› ï¸ Technology Stack

| Component | Technology | Notes |
|-----------|-----------|-------|
| **TTS** | XTTS-v2 | Multilingual voice cloning |
| **Avatar** | LivePortrait | Single-image animation (placeholder) |
| **ASR** | faster-whisper | Phase 3 |
| **LLM** | Qwen-2.5 | Phase 2+ |
| **API** | FastAPI | Python async |
| **Container** | Docker | CPU (local) / GPU (prod) |
| **Orchestration** | Docker Compose | Local dev |
| **Cloud** | GCP Cloud Run GPU | Production |

## ðŸŽ¯ Performance Targets

- **Resolution**: 256p-360p (latency > quality)
- **FPS**: 25-30
- **Latency** (Phase 3): 450-900ms end-to-end
- **Cost**: < $100/month with scale-to-zero

## ðŸ”§ Configuration

Edit `.env` file (copy from `.env.example`):

```bash
MODE=local          # local or production
DEVICE=cpu          # cpu or cuda
LOG_LEVEL=info
DEFAULT_REFERENCE_IMAGE=bruce_neutral.jpg
```

## ðŸ“Š Development Status

### âœ… Completed (Phase 1)
- [x] Project structure and Docker setup
- [x] Runtime service with FastAPI
- [x] XTTS-v2 TTS integration
- [x] Basic avatar animation (placeholder)
- [x] Phase 1 pipeline (script â†’ video)
- [x] Evaluator with test scenarios
- [x] Metrics collection framework
- [x] Voice sample extraction

### ðŸš§ In Progress
- [ ] LivePortrait full integration
- [ ] Voice quality optimization
- [ ] Model download automation

### ðŸ“… Planned (Phase 2)
- [ ] Qwen LLM integration
- [ ] Semi-interactive chat pipeline
- [ ] React web UI
- [ ] Cloud deployment (Terraform)

### ðŸ“… Planned (Phase 3)
- [ ] faster-whisper ASR
- [ ] Real-time streaming
- [ ] WebRTC integration
- [ ] Production optimization

## ðŸ“ Notes

### Model Downloads
On first run, XTTS-v2 models (~2GB) will be downloaded automatically. This may take several minutes.

### Voice Samples
Voice reference samples are extracted from the video files in `assets/videos/`. Ensure videos contain clear speech in each language (EN/ZH/ES).

### LivePortrait
Current implementation uses a simple video generation as a placeholder. Full LivePortrait integration requires:
- Cloning the LivePortrait repository
- Downloading pre-trained models
- GPU for acceptable performance

## ðŸ¤ Contributing

This is a personal project following the specification in `PROJECT_SPEC.md`.

## ðŸ“„ License

Private project - All rights reserved.

---

**Last Updated**: November 6, 2025
**Phase**: 1 (MVP)
**Status**: Development
